const { MODEL_DRAFT, MODEL_FINAL, TEMPERATURE_DRAFT, TEMPERATURE_FINAL, MAX_COMPLETION_TOKENS } = require('../config/ai');

// ëª¨ë¸ëª… ì •ê·œí™”: gpt-5 ì‚¬ìš©ì„ ìš°ì„ ìœ¼ë¡œ ìœ ì§€
function normalizeModelName(name) {
  const raw = (name || '').trim();
  const lower = raw.toLowerCase();
  if (!raw) return 'gpt-5';
  if (lower === 'gpt5') return 'gpt-5';
  return raw;
}

function getGenreDirective(genre) {
  return ({
    'ë¡œë§¨ìŠ¤': 'ê°ì •ì ì¸ êµê°ê³¼ ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ë¥¼ ê°•ì¡°í•˜ê³ , ìºë¦­í„° ê°„ì˜ ë¯¸ë¬˜í•œ ê°ì • ë³€í™”ë¥¼ ì„¬ì„¸í•˜ê²Œ í‘œí˜„í•´ì¤˜.',
    'ë¹„ê·¹': 'ê¹Šì€ ê°ˆë“±ê³¼ ë¹„ê·¹ì  ìš´ëª…ì„ ë‹¤ë£¨ë©°, ì¸ë¬¼ì˜ ë‚´ë©´ì  ê³ ë‡Œì™€ ìŠ¬í””ì„ ì§„ì¤‘í•˜ê²Œ í‘œí˜„í•´ì¤˜.',
    'ì½”ë¯¸ë””': 'ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ê²½ì¾Œí•œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ë©°, ì¬ì¹˜ ìˆëŠ” ëŒ€í™”ì™€ ìƒí™©ì„ ë§Œë“¤ì–´ì¤˜.',
    'ìŠ¤ë¦´ëŸ¬': 'ê¸´ì¥ê° ìˆëŠ” ë¶„ìœ„ê¸°ì™€ ì˜ˆì¸¡ë¶ˆê°€í•œ ì „ê°œë¡œ ê¸´ì¥ê°ì„ ì§€ì†ì‹œì¼œì¤˜.',
    'ì•¡ì…˜': 'ë‹¤ì´ë‚˜ë¯¹í•˜ê³  ì—­ë™ì ì¸ ì¥ë©´ì„ ì—°ì¶œí•˜ë©°, ìŠ¤ë¦´ ë„˜ì¹˜ëŠ” ì•¡ì…˜ ì‹œí€€ìŠ¤ë¥¼ í¬í•¨í•´ì¤˜.',
    'ê³µí¬': 'ì„¬ëœ©í•˜ê³  ë¶ˆì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•˜ë©°, ê³µí¬ê°ì„ ìì•„ë‚´ëŠ” ìƒí™©ì„ ë§Œë“¤ì–´ì¤˜.',
    'íŒíƒ€ì§€': 'í™˜ìƒì ì´ê³  ë§ˆë²•ì ì¸ ì„¸ê³„ê´€ì„ ë°”íƒ•ìœ¼ë¡œ ìƒìƒë ¥ ë„˜ì¹˜ëŠ” ì„¤ì •ì„ í™œìš©í•´ì¤˜.',
    'SF': 'ë¯¸ë˜ì ì´ê³  ê³¼í•™ì ì¸ ì„¤ì •ì„ í™œìš©í•˜ì—¬ ê¸°ìˆ ê³¼ ì¸ê°„ì˜ ê´€ê³„ë¥¼ íƒêµ¬í•´ì¤˜.',
    'ì‹œëŒ€ê·¹': 'í•´ë‹¹ ì‹œëŒ€ì˜ ë°°ê²½ê³¼ ë¬¸í™”ë¥¼ ê³ ì¦í•˜ì—¬ ì‹œëŒ€ì  íŠ¹ìƒ‰ì„ ì˜ ì‚´ë ¤ì¤˜.'
  }[genre]) || 'ì„ íƒí•œ ì¥ë¥´ì— ë§ê²Œ í†¤ê³¼ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•´ì¤˜.';
}

function parseOpenAIError(err) {
  const status = err.status || err.response?.status;
  const type = err.type || err.response?.data?.error?.type || err.code;
  const message = err.message || err.response?.data?.error?.message;

  if (type === 'insufficient_quota' || status === 402) {
    return { http: 402, code: 'insufficient_quota', msg: 'OpenAI API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í¬ë ˆë”§ì„ í™•ì¸í•´ì£¼ì„¸ìš”.' };
  }
  if (type === 'invalid_api_key' || status === 401) {
    return { http: 401, code: 'invalid_api_key', msg: 'OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.' };
  }
  if (status === 429 || type === 'rate_limit_exceeded') {
    return { http: 429, code: 'rate_limit_exceeded', msg: 'API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' };
  }
  if (type === 'unsupported_parameter' || type === 'invalid_request_error') {
    return { http: 400, code: 'invalid_request', msg: 'API ìš”ì²­ í˜•ì‹ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' };
  }
  return { http: 500, code: 'server_error', msg: 'ëŒ€ë³¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' };
}

async function callOpenAIWithRetry(openai, messages, options, { tries = 3, base = 180000 } = {}) {
  for (let i = 0; i < tries; i++) {
    try {
      // Promise.raceë¥¼ ì‚¬ìš©í•œ íƒ€ì„ì•„ì›ƒ êµ¬í˜„
      const timeoutMs = base + i * 60000; // 180s, 240s, 300s
      const modelName = normalizeModelName((options && options.model) || MODEL_FINAL);
      const temperature = (options && options.temperature) ?? TEMPERATURE_FINAL;
      const maxTokens = (options && (options.max_output_tokens || options.max_tokens || options.max_completion_tokens)) ?? MAX_COMPLETION_TOKENS;

      let apiCall;
      if (modelName.toLowerCase().startsWith('gpt-5')) {
        // gpt-5: Responses API ì‚¬ìš©
        const toText = (m) => {
          if (typeof m === 'string') return m;
          if (!m) return '';
          const role = m.role ? m.role.toUpperCase() : 'USER';
          if (typeof m.content === 'string') return `[${role}]\n${m.content}`;
          if (Array.isArray(m.content)) {
            const joined = m.content.map(c => typeof c === 'string' ? c : (c?.text || '')).join('\n');
            return `[${role}]\n${joined}`;
          }
          return `[${role}]`;
        };
        const inputText = Array.isArray(messages) ? messages.map(toText).join('\n\n') : String(messages || '');
        apiCall = openai.responses.create({
          model: modelName,
          input: inputText,
          temperature,
          max_output_tokens: maxTokens,
        }).then(r => {
          // Responses API í…ìŠ¤íŠ¸ ì•ˆì „ ì¶”ì¶œ
          let text = '';
          if (r && typeof r.output_text === 'string' && r.output_text.length > 0) {
            text = r.output_text;
          } else if (Array.isArray(r.output)) {
            try {
              const parts = [];
              for (const item of r.output) {
                if (Array.isArray(item?.content)) {
                  for (const c of item.content) {
                    if (typeof c?.text?.value === 'string') parts.push(c.text.value);
                    else if (typeof c?.text === 'string') parts.push(c.text);
                  }
                }
              }
              text = parts.join('\n').trim();
            } catch (_) {
              text = '';
            }
          }
          return { choices: [{ message: { content: text } }] };
        });
      } else {
        // ê¸°ì¡´ Chat Completions ê²½ë¡œ
        const payload = {
          model: modelName,
          messages: messages,
          temperature,
          max_tokens: maxTokens,
        };
        apiCall = openai.chat.completions.create(payload);
      }
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Request timeout')), timeoutMs)
      );
      
      const result = await Promise.race([apiCall, timeoutPromise]);
      // ë¹ˆ ì‘ë‹µ ë°©ì§€: contentê°€ ë¹„ì—ˆìœ¼ë©´ ì¬ì‹œë„ íŠ¸ë¦¬ê±°
      try {
        const text = result?.choices?.[0]?.message?.content;
        if (typeof text === 'string' && text.trim().length === 0) {
          console.warn('[AI] ë¹ˆ ì‘ë‹µ ê°ì§€ â€“ ì¬ì‹œë„ ì‹œë„');
          throw new Error('Empty AI response');
        }
      } catch (e) {
        // choices êµ¬ì¡°ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜(ìƒìœ„ì—ì„œ ì²˜ë¦¬)
      }
      return result;
    } catch (e) {
      console.log(`API í˜¸ì¶œ ì‹œë„ ${i + 1}/${tries} ì‹¤íŒ¨:`, e.message);
      
      if (i === tries - 1) throw e;
      
      const status = e.status || e.response?.status;
      const type = e.type || e.response?.data?.error?.type || e.code;
      const isRetriable = [429, 500, 502, 503, 504].includes(status) || e.message === 'Request timeout';
      
      // íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ë‚˜ ìš”ì²­ í˜•ì‹ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
      if (type === 'unsupported_parameter' || type === 'invalid_request_error' || status === 400) {
        throw e;
      }
      
      if (!isRetriable) throw e;
      
      // ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ëŒ€ê¸°
      const delay = Math.min(1000 * Math.pow(2, i), 10000);
      console.log(`${delay}ms í›„ ì¬ì‹œë„...`);
      await new Promise(r => setTimeout(r, delay));
    }
  }
}

function logRequestData(req) {
  if (process.env.NODE_ENV !== 'production') {
    console.log('ğŸ“ ìš”ì²­ ë°ì´í„°(ê°œë°œ):', req.body);
  } else {
    const { characterCount, genre, length, gender, age } = req.body || {};
    console.log('ğŸ“ ìš”ì²­ ìš”ì•½(ìš´ì˜):', { characterCount, genre, length, gender, age });
  }
}

module.exports = {
  getGenreDirective,
  parseOpenAIError,
  callOpenAIWithRetry,
  logRequestData,
  MODEL_DRAFT,
  MODEL_FINAL,
  TEMPERATURE_DRAFT,
  TEMPERATURE_FINAL,
  MAX_COMPLETION_TOKENS
};
